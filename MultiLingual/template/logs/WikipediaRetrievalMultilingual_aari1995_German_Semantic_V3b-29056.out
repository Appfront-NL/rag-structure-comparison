/var/scratch/tkl206/anaconda3/envs/myenv/lib/python3.10/site-packages/transformers/utils/hub.py:105: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Some weights of BertModel were not initialized from the model checkpoint at aari1995/German_Semantic_V3b and are newly initialized: ['embeddings.position_embeddings.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
The `batch_size` argument is deprecated and will be removed in the next release. Please use `encode_kwargs = {'batch_size': ...}` to set the batch size instead.
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - WikipediaRetrievalMultilingual, s2p, multilingual 11 / 16 Subsets


Error while evaluating WikipediaRetrievalMultilingual: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/datasets/ellamind/wikipedia-2023-11-retrieval-multilingual-qrels/paths-info/ec88a7bb2da034d538e98e3122d2c98530ca1c8d
Traceback (most recent call last):
  File "/var/scratch/tkl206/anaconda3/envs/myenv/lib/python3.10/site-packages/huggingface_hub/utils/_http.py", line 409, in hf_raise_for_status
    response.raise_for_status()
  File "/var/scratch/tkl206/anaconda3/envs/myenv/lib/python3.10/site-packages/requests/models.py", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/datasets/ellamind/wikipedia-2023-11-retrieval-multilingual-qrels/paths-info/ec88a7bb2da034d538e98e3122d2c98530ca1c8d

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/tkl206/rag-structure-comparison/MultiLingual/template/python_tasks/WikipediaRetrievalMultilingual___aari1995_German_Semantic_V3b.py", line 23, in <module>
    result = evaluation.run(
  File "/var/scratch/tkl206/anaconda3/envs/myenv/lib/python3.10/site-packages/mteb/evaluation/MTEB.py", line 672, in run
    raise e
  File "/var/scratch/tkl206/anaconda3/envs/myenv/lib/python3.10/site-packages/mteb/evaluation/MTEB.py", line 576, in run
    task.load_data(**kwargs)
  File "/var/scratch/tkl206/anaconda3/envs/myenv/lib/python3.10/site-packages/mteb/tasks/Retrieval/multilingual/WikipediaRetrievalMultilingual.py", line 121, in load_data
    self.corpus, self.queries, self.relevant_docs = _load_data(
  File "/var/scratch/tkl206/anaconda3/envs/myenv/lib/python3.10/site-packages/mteb/tasks/Retrieval/multilingual/WikipediaRetrievalMultilingual.py", line 62, in _load_data
    qrels_lang = load_dataset(
  File "/var/scratch/tkl206/anaconda3/envs/myenv/lib/python3.10/site-packages/datasets/load.py", line 2062, in load_dataset
    builder_instance = load_dataset_builder(
  File "/var/scratch/tkl206/anaconda3/envs/myenv/lib/python3.10/site-packages/datasets/load.py", line 1819, in load_dataset_builder
    builder_instance: DatasetBuilder = builder_cls(
  File "/var/scratch/tkl206/anaconda3/envs/myenv/lib/python3.10/site-packages/datasets/builder.py", line 343, in __init__
    self.config, self.config_id = self._create_builder_config(
  File "/var/scratch/tkl206/anaconda3/envs/myenv/lib/python3.10/site-packages/datasets/builder.py", line 598, in _create_builder_config
    builder_config._resolve_data_files(
  File "/var/scratch/tkl206/anaconda3/envs/myenv/lib/python3.10/site-packages/datasets/builder.py", line 207, in _resolve_data_files
    self.data_files = self.data_files.resolve(base_path, download_config)
  File "/var/scratch/tkl206/anaconda3/envs/myenv/lib/python3.10/site-packages/datasets/data_files.py", line 788, in resolve
    out[key] = data_files_patterns_list.resolve(base_path, download_config)
  File "/var/scratch/tkl206/anaconda3/envs/myenv/lib/python3.10/site-packages/datasets/data_files.py", line 741, in resolve
    resolve_pattern(
  File "/var/scratch/tkl206/anaconda3/envs/myenv/lib/python3.10/site-packages/datasets/data_files.py", line 360, in resolve_pattern
    for filepath, info in fs.glob(pattern, detail=True, **glob_kwargs).items()
  File "/var/scratch/tkl206/anaconda3/envs/myenv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 521, in glob
    return super().glob(path, **kwargs)
  File "/var/scratch/tkl206/anaconda3/envs/myenv/lib/python3.10/site-packages/fsspec/spec.py", line 609, in glob
    allpaths = self.find(root, maxdepth=depth, withdirs=True, detail=True, **kwargs)
  File "/var/scratch/tkl206/anaconda3/envs/myenv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 556, in find
    return super().find(
  File "/var/scratch/tkl206/anaconda3/envs/myenv/lib/python3.10/site-packages/fsspec/spec.py", line 500, in find
    out[path] = self.info(path)
  File "/var/scratch/tkl206/anaconda3/envs/myenv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py", line 719, in info
    paths_info = self._api.get_paths_info(
  File "/var/scratch/tkl206/anaconda3/envs/myenv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/var/scratch/tkl206/anaconda3/envs/myenv/lib/python3.10/site-packages/huggingface_hub/hf_api.py", line 3371, in get_paths_info
    hf_raise_for_status(response)
  File "/var/scratch/tkl206/anaconda3/envs/myenv/lib/python3.10/site-packages/huggingface_hub/utils/_http.py", line 482, in hf_raise_for_status
    raise _format(HfHubHTTPError, str(e), response) from e
huggingface_hub.errors.HfHubHTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/datasets/ellamind/wikipedia-2023-11-retrieval-multilingual-qrels/paths-info/ec88a7bb2da034d538e98e3122d2c98530ca1c8d
