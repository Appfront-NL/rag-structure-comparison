/var/scratch/tkl206/anaconda3/envs/myenv/lib/python3.10/site-packages/transformers/utils/hub.py:105: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Some weights of BertModel were not initialized from the model checkpoint at aari1995/German_Semantic_V3b and are newly initialized: ['embeddings.position_embeddings.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
The `batch_size` argument is deprecated and will be removed in the next release. Please use `encode_kwargs = {'batch_size': ...}` to set the batch size instead.
─────────────────────────────── Selected tasks  ────────────────────────────────
STS
    - STS12, s2s


BertSdpaSelfAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support non-absolute `position_embedding_type` or `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
Traceback (most recent call last):
  File "/home/tkl206/rag-structure-comparison/MultiLingual/template/python_tasks/STS12STS___aari1995_German_Semantic_V3b.py", line 29, in <module>
    for task_name, subsets in result.items():
AttributeError: 'list' object has no attribute 'items'
